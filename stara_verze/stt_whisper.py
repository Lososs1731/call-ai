from openai import OpenAI
import pyaudio
import wave
import tempfile
import os
from config import Config

class WhisperSTT:
    """Speech-to-Text pomoc√≠ OpenAI Whisper"""
    
    def __init__(self):
        """Inicializace Whisper STT"""
        self.client = OpenAI(api_key=Config.OPENAI_API_KEY)
        
        # Audio parametry
        self.rate = 16000
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        
        print("üé§ Speech-to-Text inicializov√°n (OpenAI Whisper)!")
        print(f"üåç Jazyk: ƒçe≈°tina")
    
    def listen_once(self, duration=5):
        """
        Nahraje audio a p≈ôep√≠≈°e ho pomoc√≠ Whisper
        
        Args:
            duration (int): D√©lka nahr√°v√°n√≠ v sekund√°ch
            
        Returns:
            str: P≈ôepsan√Ω text
        """
        print(f"\nüé§ Poslouch√°m {duration} sekund... (mluv teƒè)")
        
        audio_interface = pyaudio.PyAudio()
        
        try:
            # Otev≈ôen√≠ mikrofonu
            stream = audio_interface.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk
            )
            
            # Nahr√°v√°n√≠
            frames = []
            for i in range(0, int(self.rate / self.chunk * duration)):
                data = stream.read(self.chunk, exception_on_overflow=False)
                frames.append(data)
                
                # Progress indik√°tor
                if i % 10 == 0:
                    print("üî¥", end="", flush=True)
            
            print(" ‚úÖ")
            
            # Ukonƒçen√≠ nahr√°v√°n√≠
            stream.stop_stream()
            stream.close()
            
            # Ulo≈æen√≠ do doƒçasn√©ho WAV souboru
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_audio:
                temp_filename = temp_audio.name
                
                wf = wave.open(temp_filename, 'wb')
                wf.setnchannels(self.channels)
                wf.setsampwidth(audio_interface.get_sample_size(self.format))
                wf.setframerate(self.rate)
                wf.writeframes(b''.join(frames))
                wf.close()
            
            # P≈ôepis pomoc√≠ Whisper
            print("üîÑ Zpracov√°v√°m...")
            
            with open(temp_filename, 'rb') as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="cs"  # ƒåe≈°tina
                )
            
            # Smaz√°n√≠ doƒçasn√©ho souboru
            os.unlink(temp_filename)
            
            # Z√≠sk√°n√≠ textu
            text = transcript.text.strip()
            
            if text:
                print(f"‚úÖ Rozpozn√°no: {text}")
                return text
            else:
                print("‚ùå Nic nebylo rozpozn√°no")
                return None
                
        except Exception as e:
            print(f"‚ùå Chyba p≈ôi rozpozn√°v√°n√≠ ≈ôeƒçi: {str(e)}")
            return None
            
        finally:
            audio_interface.terminate()